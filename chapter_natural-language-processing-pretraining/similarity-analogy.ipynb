{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Artemiswe/d2l/blob/main/chapter_natural-language-processing-pretraining/similarity-analogy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09b45c17",
      "metadata": {
        "id": "09b45c17"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "011a9dcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "011a9dcd",
        "outputId": "cae9493f-95bc-4f94-925d-94f03b8dc25d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
            "Collecting jupyter==1.0.0 (from d2l)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting numpy==1.23.5 (from d2l)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting matplotlib==3.7.2 (from d2l)\n",
            "  Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting matplotlib-inline==0.1.6 (from d2l)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting requests==2.31.0 (from d2l)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pandas==2.0.3 (from d2l)\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy==1.10.1 (from d2l)\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (6.5.7)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l)\n",
            "  Downloading qtconsole-5.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (11.1.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from matplotlib-inline==0.1.6->d2l) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.18.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.2.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l)\n",
            "  Downloading QtPy-2.4.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (4.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (4.13.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.1)\n",
            "Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.6.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QtPy-2.4.3-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests, qtpy, pyparsing, numpy, matplotlib-inline, jedi, scipy, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: matplotlib-inline\n",
            "    Found existing installation: matplotlib-inline 0.1.7\n",
            "    Uninstalling matplotlib-inline-0.1.7:\n",
            "      Successfully uninstalled matplotlib-inline-0.1.7\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "cvxpy 1.6.4 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "mizani 0.13.2 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed d2l-1.0.3 jedi-0.19.2 jupyter-1.0.0 matplotlib-3.7.2 matplotlib-inline-0.1.6 numpy-1.23.5 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.6.1 qtpy-2.4.3 requests-2.31.0 scipy-1.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "1f64f73327e74f4a88312473925e46e8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install d2l\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0160c8de",
      "metadata": {
        "origin_pos": 0,
        "id": "0160c8de"
      },
      "source": [
        "# 词的相似性和类比任务\n",
        ":label:`sec_synonyms`\n",
        "\n",
        "在 :numref:`sec_word2vec_pretraining`中，我们在一个小的数据集上训练了一个word2vec模型，并使用它为一个输入词寻找语义相似的词。实际上，在大型语料库上预先训练的词向量可以应用于下游的自然语言处理任务，这将在后面的 :numref:`chap_nlp_app`中讨论。为了直观地演示大型语料库中预训练词向量的语义，让我们将预训练词向量应用到词的相似性和类比任务中。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f23dc33a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:41.256400Z",
          "iopub.status.busy": "2023-08-18T07:06:41.255749Z",
          "iopub.status.idle": "2023-08-18T07:06:43.288113Z",
          "shell.execute_reply": "2023-08-18T07:06:43.287240Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "f23dc33a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce6db3d6",
      "metadata": {
        "origin_pos": 4,
        "id": "ce6db3d6"
      },
      "source": [
        "## 加载预训练词向量\n",
        "\n",
        "以下列出维度为50、100和300的预训练GloVe嵌入，可从[GloVe网站](https://nlp.stanford.edu/projects/glove/)下载。预训练的fastText嵌入有多种语言。这里我们使用可以从[fastText网站](https://fasttext.cc/)下载300维度的英文版本（“wiki.en”）。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "89f705ca",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:43.292543Z",
          "iopub.status.busy": "2023-08-18T07:06:43.291837Z",
          "iopub.status.idle": "2023-08-18T07:06:43.297097Z",
          "shell.execute_reply": "2023-08-18T07:06:43.296299Z"
        },
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "89f705ca"
      },
      "outputs": [],
      "source": [
        "#@save\n",
        "d2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\n",
        "                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n",
        "\n",
        "#@save\n",
        "d2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\n",
        "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n",
        "\n",
        "#@save\n",
        "d2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\n",
        "                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n",
        "\n",
        "#@save\n",
        "d2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\n",
        "                           'c1816da3821ae9f43899be655002f6c723e91b88')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8368bbae",
      "metadata": {
        "origin_pos": 6,
        "id": "8368bbae"
      },
      "source": [
        "为了加载这些预训练的GloVe和fastText嵌入，我们定义了以下`TokenEmbedding`类。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cd54118c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:43.300883Z",
          "iopub.status.busy": "2023-08-18T07:06:43.300205Z",
          "iopub.status.idle": "2023-08-18T07:06:43.309328Z",
          "shell.execute_reply": "2023-08-18T07:06:43.308481Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "cd54118c"
      },
      "outputs": [],
      "source": [
        "#@save\n",
        "class TokenEmbedding:\n",
        "    \"\"\"GloVe嵌入\"\"\"\n",
        "    def __init__(self, embedding_name):\n",
        "        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n",
        "            embedding_name)\n",
        "        self.unknown_idx = 0\n",
        "        self.token_to_idx = {token: idx for idx, token in\n",
        "                             enumerate(self.idx_to_token)}\n",
        "\n",
        "    def _load_embedding(self, embedding_name):\n",
        "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
        "        data_dir = d2l.download_extract(embedding_name)\n",
        "        # GloVe网站：https://nlp.stanford.edu/projects/glove/\n",
        "        # fastText网站：https://fasttext.cc/\n",
        "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
        "            for line in f:\n",
        "                elems = line.rstrip().split(' ')\n",
        "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
        "                # 跳过标题信息，例如fastText中的首行\n",
        "                if len(elems) > 1:\n",
        "                    idx_to_token.append(token)\n",
        "                    idx_to_vec.append(elems)\n",
        "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
        "        return idx_to_token, torch.tensor(idx_to_vec)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
        "                   for token in tokens]\n",
        "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
        "        return vecs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6375fd2e",
      "metadata": {
        "origin_pos": 8,
        "id": "6375fd2e"
      },
      "source": [
        "下面我们加载50维GloVe嵌入（在维基百科的子集上预训练）。创建`TokenEmbedding`实例时，如果尚未下载指定的嵌入文件，则必须下载该文件。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ac49581b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:43.312986Z",
          "iopub.status.busy": "2023-08-18T07:06:43.312409Z",
          "iopub.status.idle": "2023-08-18T07:06:54.396038Z",
          "shell.execute_reply": "2023-08-18T07:06:54.395176Z"
        },
        "origin_pos": 9,
        "tab": [
          "pytorch"
        ],
        "id": "ac49581b"
      },
      "outputs": [],
      "source": [
        "glove_6b50d = TokenEmbedding('glove.6b.50d')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f30d4e",
      "metadata": {
        "origin_pos": 10,
        "id": "57f30d4e"
      },
      "source": [
        "输出词表大小。词表包含400000个词（词元）和一个特殊的未知词元。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5d91a982",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.400162Z",
          "iopub.status.busy": "2023-08-18T07:06:54.399579Z",
          "iopub.status.idle": "2023-08-18T07:06:54.405466Z",
          "shell.execute_reply": "2023-08-18T07:06:54.404676Z"
        },
        "origin_pos": 11,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d91a982",
        "outputId": "0224799f-31be-4585-bf2f-7e6f4828e86b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400001"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(glove_6b50d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867f2106",
      "metadata": {
        "origin_pos": 12,
        "id": "867f2106"
      },
      "source": [
        "我们可以得到词表中一个单词的索引，反之亦然。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6e10f262",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.408746Z",
          "iopub.status.busy": "2023-08-18T07:06:54.408294Z",
          "iopub.status.idle": "2023-08-18T07:06:54.413468Z",
          "shell.execute_reply": "2023-08-18T07:06:54.412687Z"
        },
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e10f262",
        "outputId": "781c5096-d2ef-4224-930c-cde635c8494b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3367, 'beautiful')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "glove_6b50d.token_to_idx['beautiful'], glove_6b50d.idx_to_token[3367]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b6c303",
      "metadata": {
        "origin_pos": 14,
        "id": "92b6c303"
      },
      "source": [
        "## 应用预训练词向量\n",
        "\n",
        "使用加载的GloVe向量，我们将通过下面的词相似性和类比任务中来展示词向量的语义。\n",
        "\n",
        "### 词相似度\n",
        "\n",
        "与 :numref:`subsec_apply-word-embed`类似，为了根据词向量之间的余弦相似性为输入词查找语义相似的词，我们实现了以下`knn`（$k$近邻）函数。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2da78732",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.416901Z",
          "iopub.status.busy": "2023-08-18T07:06:54.416268Z",
          "iopub.status.idle": "2023-08-18T07:06:54.421648Z",
          "shell.execute_reply": "2023-08-18T07:06:54.420466Z"
        },
        "origin_pos": 16,
        "tab": [
          "pytorch"
        ],
        "id": "2da78732"
      },
      "outputs": [],
      "source": [
        "def knn(W, x, k):\n",
        "    # 增加1e-9以获得数值稳定性\n",
        "    cos = torch.mv(W, x.reshape(-1,)) / (\n",
        "        torch.sqrt(torch.sum(W * W, axis=1) + 1e-9) *\n",
        "        torch.sqrt((x * x).sum()))\n",
        "    _, topk = torch.topk(cos, k=k)\n",
        "    return topk, [cos[int(i)] for i in topk]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644a758d",
      "metadata": {
        "origin_pos": 18,
        "id": "644a758d"
      },
      "source": [
        "然后，我们使用`TokenEmbedding`的实例`embed`中预训练好的词向量来搜索相似的词。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7b1da561",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.425376Z",
          "iopub.status.busy": "2023-08-18T07:06:54.424618Z",
          "iopub.status.idle": "2023-08-18T07:06:54.430025Z",
          "shell.execute_reply": "2023-08-18T07:06:54.428981Z"
        },
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ],
        "id": "7b1da561"
      },
      "outputs": [],
      "source": [
        "def get_similar_tokens(query_token, k, embed):\n",
        "    topk, cos = knn(embed.idx_to_vec, embed[[query_token]], k + 1)\n",
        "    for i, c in zip(topk[1:], cos[1:]):  # 排除输入词\n",
        "        print(f'{embed.idx_to_token[int(i)]}：cosine相似度={float(c):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ba6f5c8",
      "metadata": {
        "origin_pos": 20,
        "id": "6ba6f5c8"
      },
      "source": [
        "`glove_6b50d`中预训练词向量的词表包含400000个词和一个特殊的未知词元。排除输入词和未知词元后，我们在词表中找到与“chip”一词语义最相似的三个词。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "623bc4a9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.433258Z",
          "iopub.status.busy": "2023-08-18T07:06:54.432943Z",
          "iopub.status.idle": "2023-08-18T07:06:54.481827Z",
          "shell.execute_reply": "2023-08-18T07:06:54.480628Z"
        },
        "origin_pos": 21,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "623bc4a9",
        "outputId": "d66cf8b4-a591-49ca-fc90-55d0dc34afad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chips：cosine相似度=0.856\n",
            "intel：cosine相似度=0.749\n",
            "electronics：cosine相似度=0.749\n"
          ]
        }
      ],
      "source": [
        "get_similar_tokens('chip', 3, glove_6b50d)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWIdmD0MmZpR"
      },
      "id": "OWIdmD0MmZpR",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c18fa17a",
      "metadata": {
        "origin_pos": 22,
        "id": "c18fa17a"
      },
      "source": [
        "下面输出与“baby”和“beautiful”相似的词。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d2fd5e8f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.486458Z",
          "iopub.status.busy": "2023-08-18T07:06:54.485962Z",
          "iopub.status.idle": "2023-08-18T07:06:54.508991Z",
          "shell.execute_reply": "2023-08-18T07:06:54.507938Z"
        },
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2fd5e8f",
        "outputId": "95cae111-4150-404c-bd38-d5cede861dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "babies：cosine相似度=0.839\n",
            "boy：cosine相似度=0.800\n",
            "girl：cosine相似度=0.792\n"
          ]
        }
      ],
      "source": [
        "get_similar_tokens('baby', 3, glove_6b50d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "faa9e2e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.513356Z",
          "iopub.status.busy": "2023-08-18T07:06:54.512976Z",
          "iopub.status.idle": "2023-08-18T07:06:54.534489Z",
          "shell.execute_reply": "2023-08-18T07:06:54.533425Z"
        },
        "origin_pos": 24,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faa9e2e2",
        "outputId": "63fdfed1-d187-4bf9-a4b7-74977e5458e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lovely：cosine相似度=0.921\n",
            "gorgeous：cosine相似度=0.893\n",
            "wonderful：cosine相似度=0.830\n"
          ]
        }
      ],
      "source": [
        "get_similar_tokens('beautiful', 3, glove_6b50d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc0553d",
      "metadata": {
        "origin_pos": 25,
        "id": "5cc0553d"
      },
      "source": [
        "### 词类比\n",
        "\n",
        "除了找到相似的词，我们还可以将词向量应用到词类比任务中。\n",
        "例如，“man” : “woman” :: “son” : “daughter”是一个词的类比。\n",
        "“man”是对“woman”的类比，“son”是对“daughter”的类比。\n",
        "具体来说，词类比任务可以定义为：\n",
        "对于单词类比$a : b :: c : d$，给出前三个词$a$、$b$和$c$，找到$d$。\n",
        "用$\\text{vec}(w)$表示词$w$的向量，\n",
        "为了完成这个类比，我们将找到一个词，\n",
        "其向量与$\\text{vec}(c)+\\text{vec}(b)-\\text{vec}(a)$的结果最相似。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e5340469",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.539108Z",
          "iopub.status.busy": "2023-08-18T07:06:54.538593Z",
          "iopub.status.idle": "2023-08-18T07:06:54.544150Z",
          "shell.execute_reply": "2023-08-18T07:06:54.543191Z"
        },
        "origin_pos": 26,
        "tab": [
          "pytorch"
        ],
        "id": "e5340469"
      },
      "outputs": [],
      "source": [
        "def get_analogy(token_a, token_b, token_c, embed):\n",
        "    vecs = embed[[token_a, token_b, token_c]]\n",
        "    x = vecs[1] - vecs[0] + vecs[2]\n",
        "    topk, cos = knn(embed.idx_to_vec, x, 1)\n",
        "    return embed.idx_to_token[int(topk[0])]  # 删除未知词"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df8f2721",
      "metadata": {
        "origin_pos": 27,
        "id": "df8f2721"
      },
      "source": [
        "让我们使用加载的词向量来验证“male-female”类比。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e91de1ce",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.548236Z",
          "iopub.status.busy": "2023-08-18T07:06:54.547963Z",
          "iopub.status.idle": "2023-08-18T07:06:54.569097Z",
          "shell.execute_reply": "2023-08-18T07:06:54.568018Z"
        },
        "origin_pos": 28,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e91de1ce",
        "outputId": "ee9aa41f-2463-4c6f-c4bc-3c2908ddaaf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'daughter'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "get_analogy('man', 'woman', 'son', glove_6b50d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b1ce80",
      "metadata": {
        "origin_pos": 29,
        "id": "d9b1ce80"
      },
      "source": [
        "下面完成一个“首都-国家”的类比：\n",
        "“beijing” : “china” :: “tokyo” : “japan”。\n",
        "这说明了预训练词向量中的语义。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "16eb56d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.573551Z",
          "iopub.status.busy": "2023-08-18T07:06:54.573270Z",
          "iopub.status.idle": "2023-08-18T07:06:54.595104Z",
          "shell.execute_reply": "2023-08-18T07:06:54.594092Z"
        },
        "origin_pos": 30,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "16eb56d3",
        "outputId": "893285c6-f306-4d01-ad74-d3b29505105f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'japan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "get_analogy('beijing', 'china', 'tokyo', glove_6b50d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595634f2",
      "metadata": {
        "origin_pos": 31,
        "id": "595634f2"
      },
      "source": [
        "另外，对于“bad” : “worst” :: “big” : “biggest”等“形容词-形容词最高级”的比喻，预训练词向量可以捕捉到句法信息。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b8d6395b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.599698Z",
          "iopub.status.busy": "2023-08-18T07:06:54.599313Z",
          "iopub.status.idle": "2023-08-18T07:06:54.621533Z",
          "shell.execute_reply": "2023-08-18T07:06:54.620486Z"
        },
        "origin_pos": 32,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b8d6395b",
        "outputId": "edaecf82-a5d7-42cd-de31-f32869e45be1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'biggest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "get_analogy('bad', 'worst', 'big', glove_6b50d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6555f30",
      "metadata": {
        "origin_pos": 33,
        "id": "a6555f30"
      },
      "source": [
        "为了演示在预训练词向量中捕捉到的过去式概念，我们可以使用“现在式-过去式”的类比来测试句法：“do” : “did” :: “go” : “went”。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "986fa401",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:06:54.626086Z",
          "iopub.status.busy": "2023-08-18T07:06:54.625554Z",
          "iopub.status.idle": "2023-08-18T07:06:54.647570Z",
          "shell.execute_reply": "2023-08-18T07:06:54.646604Z"
        },
        "origin_pos": 34,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "986fa401",
        "outputId": "c452c2da-f775-46ef-a954-d2328f170eb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'went'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "get_analogy('do', 'did', 'go', glove_6b50d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61371af5",
      "metadata": {
        "origin_pos": 35,
        "id": "61371af5"
      },
      "source": [
        "## 小结\n",
        "\n",
        "* 在实践中，在大型语料库上预先练的词向量可以应用于下游的自然语言处理任务。\n",
        "* 预训练的词向量可以应用于词的相似性和类比任务。\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 使用`TokenEmbedding('wiki.en')`测试fastText结果。\n",
        "1. 当词表非常大时，我们怎样才能更快地找到相似的词或完成一个词的类比呢？\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.\n",
        "fastText300 = TokenEmbedding('wiki.en')\n",
        "get_similar_tokens('chip', 3, fastText300)\n",
        "get_similar_tokens('baby', 3, fastText300)\n",
        "get_similar_tokens('beautiful', 3, fastText300)\n",
        "get_analogy('man', 'woman', 'son', fastText300)\n",
        "get_analogy('beijing', 'china', 'tokyo', fastText300)\n",
        "\n"
      ],
      "metadata": {
        "id": "erKxMumzmE6e"
      },
      "id": "erKxMumzmE6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#使用FAISS加速相似词搜索\n",
        "import faiss\n",
        "\n",
        "def get_similar_tokens_faiss(query_token, k, embed):\n",
        "\n",
        "    index = faiss.IndexFlatIP(embed.idx_to_vec.shape[1])\n",
        "    index.add(embed.idx_to_vec)\n",
        "\n",
        "    query_vec = embed[[query_token]]\n",
        "\n",
        "\n",
        "    D, I = index.search(query_vec, k + 1)\n",
        "\n",
        "\n",
        "    for i, c in zip(I[0][1:], D[0][1:]):\n",
        "        print(f'{embed.idx_to_token[int(i)]}：cosine相似度={float(c):.3f}')\n",
        "\n",
        "get_similar_tokens_faiss('chip', 3, glove_6b50d)\n",
        "\n",
        "\n",
        "def get_analogy_faiss(token_a, token_b, token_c, embed):\n",
        "\n",
        "    index = faiss.IndexFlatIP(embed.idx_to_vec.shape[1])\n",
        "    index.add(embed.idx_to_vec)\n",
        "\n",
        "    vecs = embed[[token_a, token_b, token_c]]\n",
        "    x = vecs[1] - vecs[0] + vecs[2]\n",
        "\n",
        "\n",
        "    D, I = index.search(x.unsqueeze(0), 1)\n",
        "\n",
        "    return embed.idx_to_token[int(I[0][0])]\n",
        "\n",
        "\n",
        "get_analogy_faiss('man', 'woman', 'son', glove_6b50d)\n"
      ],
      "metadata": {
        "id": "eL6G71NkmwYb"
      },
      "id": "eL6G71NkmwYb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bfebf384",
      "metadata": {
        "origin_pos": 37,
        "tab": [
          "pytorch"
        ],
        "id": "bfebf384"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/5746)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}